{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.6\n"
     ]
    }
   ],
   "source": [
    "#Verify Keras Install\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Array Functionality\n",
    "import numpy as np\n",
    "np.random.seed(1032017) #Make the same net every time this notebook is run, change for a different net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras functions\n",
    "\n",
    "#Container for the neural net\n",
    "from keras.models import Sequential\n",
    "#Basic Neural Net Layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#Convolutional Neural Net Layers\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "#Misc keras functionality\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataset\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulate the input data to make it readable for the CNN\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1) #this would be 1, 28, 28 for theano\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1) #this would be 1, 28, 28 for theano\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Manipulate the output data to make it readable for the CNN\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Verify correct data shape\n",
    "print(X_train.shape) #(60000, 1, 28, 28)\n",
    "print(Y_train.shape) #(60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFirst parameter is the number of 'filters' that will learn features on the images\\nSecond parameter is the number of rows/collumns in each filter\\nactivation is the activation function that we are using for this layer\\ninput_shape lets keras know what the input to the Neural Net is (only needed on first layer)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the model\n",
    "model = Sequential() #Holds all of the layers\n",
    "#First hidden layer\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "'''\n",
    "First parameter is the number of 'filters' that will learn features on the images\n",
    "Second parameter is the number of rows/collumns in each filter\n",
    "activation is the activation function that we are using for this layer\n",
    "input_shape lets keras know what the input to the Neural Net is (only needed on first layer)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOutput layer must have the same number of neurons as the size of the output\\nsoftmax activation function makes it so the outputs act as a percent chance \\n(or membership value, if you are feeling fuzzy)\\nthat this class is the right one (According to the model)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second hidden layer\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "'''\n",
    "Same as the previous layer, but we do not need to specify the input shape\n",
    "We could change these parameters as we see fit\n",
    "'''\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "'''\n",
    "MaxPooling reduces the dimensionality of the current data by taking the max of each nxm area\n",
    "(2,2) would halve the input dimensionality\n",
    "'''\n",
    "model.add(Dropout(0.25))\n",
    "'''\n",
    "Training optimizer that makes networks less likely to overfit\n",
    "Parameter is the likelyhood that the neuron is present at TRAINING TIME (once the model is trained, dropout is incative)\n",
    "'''\n",
    "model.add(Flatten())\n",
    "'''\n",
    "Makes the output flat so that we can feed it into a densely connected layer\n",
    "'''\n",
    "#Third Hidden Layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "'''\n",
    "Your basic neural net layer\n",
    "first parameter is the number of neurons at this layer\n",
    "second paramer is the activation function to use\n",
    "'''\n",
    "model.add(Dropout(0.5))\n",
    "'''\n",
    "Another dropout layer\n",
    "'''\n",
    "#Output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "'''\n",
    "Output layer must have the same number of neurons as the size of the output\n",
    "softmax activation function makes it so the outputs act as a percent chance \n",
    "(or membership value, if you are feeling fuzzy)\n",
    "that this class is the right one (According to the model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nloss is the loss function to use\\noptimzer is the optimizer to use\\nmetrics are computed at the end of each epoch to tell the user how well the model is doing\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "'''\n",
    "loss is the loss function to use\n",
    "optimzer is the optimizer to use\n",
    "metrics are computed at the end of each epoch to tell the user how well the model is doing\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 24s - loss: 0.2207 - acc: 0.9338    \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 20s - loss: 0.0906 - acc: 0.9734    \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0680 - acc: 0.9788    \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0575 - acc: 0.9824    \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0486 - acc: 0.9851    \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0412 - acc: 0.9871    \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0374 - acc: 0.9883    \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0346 - acc: 0.9891    \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0316 - acc: 0.9901    \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s - loss: 0.0295 - acc: 0.9904    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfirst parameter is the collection of input datapoints to feed into the net\\nsecond parameter is the desired output\\nbatch_size is the number of training points to show the net before weights are updated\\nepochs is the number of times the whole set of training points will be shown to the network\\nverbose gives more or less output to the user\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)\n",
    "'''\n",
    "first parameter is the collection of input datapoints to feed into the net\n",
    "second parameter is the desired output\n",
    "batch_size is the number of training points to show the net before weights are updated\n",
    "epochs is the number of times the whole set of training points will be shown to the network\n",
    "verbose gives more or less output to the user\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.029269055708581983, 0.99160000000000004]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "'''\n",
    "X_test and Y_test have been witheld from the model, so this will tell us how accurate the model is\n",
    "If the loss or accuracy are much lower than the training loss or accuracy, then the model is most likely overfit\n",
    "Thus, fewer epochs should be run in the future, or more data should be aquired\n",
    "'''\n",
    "print(score) #[loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCode from:\\nhttps://elitedatascience.com/keras-tutorial-deep-learning-in-python\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Code from:\n",
    "https://elitedatascience.com/keras-tutorial-deep-learning-in-python\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
